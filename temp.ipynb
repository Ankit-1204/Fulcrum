{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pickle\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='http://localhost:3000/auth/login'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJkYXRhIjoiYW5raXRfMTIzIiwiaWF0IjoxNzM3NDExMjYzLCJleHAiOjE3Mzc0MTg0NjN9.8VRdsNkd7zofdCay8QbHLl1xAXLNSsrHd5E_Uq21iP8', 'user': 'ankit_123'}\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "model_path=\"Task_Classifier.pkl\"\n",
    "script_path=\"script.py\"\n",
    "require=\"requirement.txt\"\n",
    "\n",
    "print(data)\n",
    "with open(model_path,'rb') as model, open(script_path,'rb') as script, open(require,'rb') as requirements:       \n",
    "            file={'model': model,\n",
    "            'script': script,\n",
    "            'requirements': requirements}\n",
    "            header={'Authorization' : data['token']}\n",
    "            payload={'user':data['user']}\n",
    "            up_url=f'http://localhost:3000/upload'\n",
    "            response=requests.post(up_url,headers=header,data=payload,files=file)\n",
    "            print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'File Uploaded and Environment created'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"File Uploaded Successfully\",\"file\":{\"fieldname\":\"file\",\"originalname\":\"Task_Classifier.pkl\",\"encoding\":\"7bit\",\"mimetype\":\"text/plain\",\"destination\":\"upload\\\\ankit_123\",\"filename\":\"Task_Classifier.pkl\",\"path\":\"upload\\\\ankit_123\\\\Task_Classifier.pkl\",\"size\":5708}}\n"
     ]
    }
   ],
   "source": [
    "with open('backend\\Task_Classifier.pkl','rb') as model:\n",
    "        file={'file':model}\n",
    "        header={'Authorization' : data['token']}\n",
    "        payload={'model_type':'model_type','user':data['user']}\n",
    "        up_url=f'http://localhost:3000/upload'\n",
    "        response=requests.post(up_url,headers=header,data=payload,files=file)\n",
    "        print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload={'username':'ankit_upadhyay','password':'abcd_123'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='http://localhost:3000/auth/login'\n",
    "payload={'username':'ankit_123','password':'abcd_100'}\n",
    "token=requests.post(url,json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJkYXRhIjoiYW5raXRfMTIzIiwiaWF0IjoxNzM3NDExMjYzLCJleHAiOjE3Mzc0MTg0NjN9.8VRdsNkd7zofdCay8QbHLl1xAXLNSsrHd5E_Uq21iP8',\n",
       " 'user': 'ankit_123'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=token.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_url=f'http://localhost:3000/download/model/Task_Classifier.pkl'\n",
    "header={'Authorization' : data['token']}\n",
    "payload={'model_type':'model_type','user':data['user']}\n",
    "response=requests.post(up_url,headers=header,json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mbackend\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTask_Classifier.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m----> 2\u001b[0m     model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(file)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\__init__.py:82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __check_build  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[0;32m     83\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[0;32m     85\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     86\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mshow_versions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tags\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     _DEFAULT_TAGS,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m check_X_y\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m DataConversionWarning\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeprecation\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_version, threadpool_info\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_estimator_html_repr\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     as_float_array,\n\u001b[0;32m     33\u001b[0m     assert_all_finite,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     check_scalar,\n\u001b[0;32m     42\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthreadpoolctl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m config_context, get_config\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\__init__.py:605\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m \n\u001b[0;32m    601\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_warnings_errors\u001b[39;00m \u001b[39mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    604\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 605\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    606\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_variation\u001b[39;00m \u001b[39mimport\u001b[39;00m variation\n\u001b[0;32m    607\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdistributions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\_stats_py.py:52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats\u001b[39;00m \u001b[39mimport\u001b[39;00m (_kendall_dis, _toint64, _weightedrankedtau,\n\u001b[0;32m     50\u001b[0m                      _local_correlations)\n\u001b[0;32m     51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataclasses\u001b[39;00m \u001b[39mimport\u001b[39;00m dataclass, field\n\u001b[1;32m---> 52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_hypotests\u001b[39;00m \u001b[39mimport\u001b[39;00m _all_partitions\n\u001b[0;32m     53\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_pythran\u001b[39;00m \u001b[39mimport\u001b[39;00m _compute_outer_prob_inside_method\n\u001b[0;32m     54\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_resampling\u001b[39;00m \u001b[39mimport\u001b[39;00m (MonteCarloMethod, PermutationMethod, BootstrapMethod,\n\u001b[0;32m     55\u001b[0m                           monte_carlo_test, permutation_test, bootstrap,\n\u001b[0;32m     56\u001b[0m                           _batch_generator)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\_hypotests.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_continuous_distns\u001b[39;00m \u001b[39mimport\u001b[39;00m chi2, norm\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m \u001b[39mimport\u001b[39;00m gamma, kv, gammaln\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfft\u001b[39;00m \u001b[39mimport\u001b[39;00m ifft\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_pythran\u001b[39;00m \u001b[39mimport\u001b[39;00m _a_ij_Aij_Dij2\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_pythran\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     _concordant_pairs \u001b[39mas\u001b[39;00m _P, _discordant_pairs \u001b[39mas\u001b[39;00m _Q\n\u001b[0;32m     17\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\fft\\__init__.py:85\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m==============================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mDiscrete Fourier transforms (:mod:`scipy.fft`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \n\u001b[0;32m     83\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_basic\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     86\u001b[0m     fft, ifft, fft2, ifft2, fftn, ifftn,\n\u001b[0;32m     87\u001b[0m     rfft, irfft, rfft2, irfft2, rfftn, irfftn,\n\u001b[0;32m     88\u001b[0m     hfft, ihfft, hfft2, ihfft2, hfftn, ihfftn)\n\u001b[0;32m     89\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_realtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m dct, idct, dst, idst, dctn, idctn, dstn, idstn\n\u001b[0;32m     90\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_fftlog\u001b[39;00m \u001b[39mimport\u001b[39;00m fht, ifht, fhtoffset\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\fft\\_basic.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39muarray\u001b[39;00m \u001b[39mimport\u001b[39;00m generate_multimethod, Dispatchable\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_x_replacer\u001b[39m(args, kwargs, dispatchables):\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\_lib\\uarray.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39muarray\u001b[39;00m \u001b[39mimport\u001b[39;00m _Function\n\u001b[0;32m     27\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_uarray\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_uarray\u001b[39;00m \u001b[39mimport\u001b[39;00m _Function  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39mdel\u001b[39;00m _has_uarray\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\_lib\\_uarray\\__init__.py:115\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m.. note:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m    If you are looking for overrides for NumPy-specific methods, see the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mwill not be possible.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_backend\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    116\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m0.8.8.dev0+aa94c5a4.scipy\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\_lib\\_uarray\\_backend.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _uarray\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcopyreg\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('backend\\Task_Classifier.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test=pd.read_csv('backend/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type DataFrame is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m header\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mAuthorization\u001b[39m\u001b[39m'\u001b[39m : data[\u001b[39m'\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[0;32m      3\u001b[0m payload\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mTask_Classifier.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m:data[\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m],\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m:test}\n\u001b[1;32m----> 4\u001b[0m response\u001b[39m=\u001b[39mrequests\u001b[39m.\u001b[39;49mpost(up_url,headers\u001b[39m=\u001b[39;49mheader,json\u001b[39m=\u001b[39;49mpayload)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url, data\u001b[39m=\u001b[39mdata, json\u001b[39m=\u001b[39mjson, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m# Create the Request.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m req \u001b[39m=\u001b[39m Request(\n\u001b[0;32m    564\u001b[0m     method\u001b[39m=\u001b[39mmethod\u001b[39m.\u001b[39mupper(),\n\u001b[0;32m    565\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    573\u001b[0m     hooks\u001b[39m=\u001b[39mhooks,\n\u001b[0;32m    574\u001b[0m )\n\u001b[1;32m--> 575\u001b[0m prep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_request(req)\n\u001b[0;32m    577\u001b[0m proxies \u001b[39m=\u001b[39m proxies \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m    579\u001b[0m settings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmerge_environment_settings(\n\u001b[0;32m    580\u001b[0m     prep\u001b[39m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[0;32m    581\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:486\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    483\u001b[0m     auth \u001b[39m=\u001b[39m get_netrc_auth(request\u001b[39m.\u001b[39murl)\n\u001b[0;32m    485\u001b[0m p \u001b[39m=\u001b[39m PreparedRequest()\n\u001b[1;32m--> 486\u001b[0m p\u001b[39m.\u001b[39;49mprepare(\n\u001b[0;32m    487\u001b[0m     method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod\u001b[39m.\u001b[39;49mupper(),\n\u001b[0;32m    488\u001b[0m     url\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m     files\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mfiles,\n\u001b[0;32m    490\u001b[0m     data\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mdata,\n\u001b[0;32m    491\u001b[0m     json\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mjson,\n\u001b[0;32m    492\u001b[0m     headers\u001b[39m=\u001b[39;49mmerge_setting(\n\u001b[0;32m    493\u001b[0m         request\u001b[39m.\u001b[39;49mheaders, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders, dict_class\u001b[39m=\u001b[39;49mCaseInsensitiveDict\n\u001b[0;32m    494\u001b[0m     ),\n\u001b[0;32m    495\u001b[0m     params\u001b[39m=\u001b[39;49mmerge_setting(request\u001b[39m.\u001b[39;49mparams, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams),\n\u001b[0;32m    496\u001b[0m     auth\u001b[39m=\u001b[39;49mmerge_setting(auth, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauth),\n\u001b[0;32m    497\u001b[0m     cookies\u001b[39m=\u001b[39;49mmerged_cookies,\n\u001b[0;32m    498\u001b[0m     hooks\u001b[39m=\u001b[39;49mmerge_hooks(request\u001b[39m.\u001b[39;49mhooks, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhooks),\n\u001b[0;32m    499\u001b[0m )\n\u001b[0;32m    500\u001b[0m \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\models.py:371\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_headers(headers)\n\u001b[0;32m    370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_cookies(cookies)\n\u001b[1;32m--> 371\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_body(data, files, json)\n\u001b[0;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_auth(auth, url)\n\u001b[0;32m    374\u001b[0m \u001b[39m# Note that prepare_auth must be last to enable authentication schemes\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[39m# such as OAuth to work on a fully prepared request.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39m# This MUST go after prepare_auth. Authenticators could add a hook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\models.py:511\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_body\u001b[1;34m(self, data, files, json)\u001b[0m\n\u001b[0;32m    508\u001b[0m content_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m     body \u001b[39m=\u001b[39m complexjson\u001b[39m.\u001b[39;49mdumps(json, allow_nan\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    512\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ve:\n\u001b[0;32m    513\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidJSONError(ve, request\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n\u001b[0;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[0;32m    235\u001b[0m     skipkeys\u001b[39m=\u001b[39;49mskipkeys, ensure_ascii\u001b[39m=\u001b[39;49mensure_ascii,\n\u001b[0;32m    236\u001b[0m     check_circular\u001b[39m=\u001b[39;49mcheck_circular, allow_nan\u001b[39m=\u001b[39;49mallow_nan, indent\u001b[39m=\u001b[39;49mindent,\n\u001b[0;32m    237\u001b[0m     separators\u001b[39m=\u001b[39;49mseparators, default\u001b[39m=\u001b[39;49mdefault, sort_keys\u001b[39m=\u001b[39;49msort_keys,\n\u001b[1;32m--> 238\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\u001b[39m.\u001b[39;49mencode(obj)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    196\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    201\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[0;32m    254\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[0;32m    255\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[0;32m    256\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type DataFrame is not JSON serializable"
     ]
    }
   ],
   "source": [
    "up_url=f'http://localhost:3000/predict'\n",
    "header={'Authorization' : data['token']}\n",
    "payload={'model_name':'Task_Classifier.pkl','user':data['user'],'input':test}\n",
    "response=requests.post(up_url,headers=header,json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, player: str, env_cfg) -> None:\n",
    "        # ... [existing initialization code] ...\n",
    "        \n",
    "        # Visitation counting\n",
    "        self.position_visits = {}  # Track visited positions\n",
    "        self.state_visits = {}    # Track visited states\n",
    "        \n",
    "        # Curiosity Network - predicts next state\n",
    "        self.curiosity_net = nn.Sequential(\n",
    "            nn.Linear(12 + 5, 64),  # state dim + action dim\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12)       # predicts next state\n",
    "        ).to(self.device)\n",
    "        self.curiosity_optimizer = torch.optim.Adam(self.curiosity_net.parameters(), lr=1e-4)\n",
    "        \n",
    "        # Parameters for exploration rewards\n",
    "        self.visit_decay = 0.995   # Decay rate for visit counts\n",
    "        self.curiosity_scale = 0.1  # Scale for curiosity reward\n",
    "        self.count_scale = 0.05    # Scale for count-based reward\n",
    "        self.info_gain_scale = 0.1  # Scale for information gain reward\n",
    "        \n",
    "        # Maintain running statistics for state normalization\n",
    "        self.state_mean = None\n",
    "        self.state_std = None\n",
    "        \n",
    "    def compute_exploration_rewards(self, state, action, next_state, unit_pos):\n",
    "        rewards = 0.0\n",
    "        \n",
    "        # 1. Intrinsic Motivation - Visiting New Areas\n",
    "        pos_tuple = tuple(unit_pos)\n",
    "        if pos_tuple not in self.position_visits:\n",
    "            self.position_visits[pos_tuple] = 0\n",
    "        self.position_visits[pos_tuple] += 1\n",
    "        \n",
    "        # Reward for visiting less frequented areas\n",
    "        visit_count = self.position_visits[pos_tuple]\n",
    "        area_novelty_reward = 1.0 / np.sqrt(visit_count)\n",
    "        rewards += self.count_scale * area_novelty_reward\n",
    "        \n",
    "        # Decay visit counts\n",
    "        for pos in self.position_visits:\n",
    "            self.position_visits[pos] *= self.visit_decay\n",
    "        \n",
    "        # 2. Curiosity-Based Reward\n",
    "        with torch.no_grad():\n",
    "            # Convert action to one-hot\n",
    "            action_onehot = torch.zeros(5, device=self.device)\n",
    "            action_onehot[action] = 1\n",
    "            \n",
    "            # Predict next state\n",
    "            state_action = torch.cat([state, action_onehot])\n",
    "            predicted_next_state = self.curiosity_net(state_action)\n",
    "            \n",
    "            # Curiosity reward is prediction error\n",
    "            actual_next_state = torch.FloatTensor(next_state).to(self.device)\n",
    "            prediction_error = torch.norm(predicted_next_state - actual_next_state)\n",
    "            curiosity_reward = prediction_error.item()\n",
    "            rewards += self.curiosity_scale * curiosity_reward\n",
    "        \n",
    "        # 3. Count-Based Exploration\n",
    "        state_hash = hash(tuple(state.cpu().numpy().round(decimals=2)))\n",
    "        if state_hash not in self.state_visits:\n",
    "            self.state_visits[state_hash] = 0\n",
    "        self.state_visits[state_hash] += 1\n",
    "        \n",
    "        # Reward based on state novelty\n",
    "        state_count_reward = 1.0 / np.sqrt(self.state_visits[state_hash])\n",
    "        rewards += self.count_scale * state_count_reward\n",
    "        \n",
    "        # 4. Information Gain\n",
    "        if self.state_mean is None:\n",
    "            self.state_mean = state.clone()\n",
    "            self.state_std = torch.ones_like(state)\n",
    "        else:\n",
    "            # Update running statistics\n",
    "            new_mean = 0.99 * self.state_mean + 0.01 * state\n",
    "            new_std = torch.sqrt(0.99 * (self.state_std ** 2) + 0.01 * (state - self.state_mean) ** 2)\n",
    "            \n",
    "            # Information gain is KL divergence between old and new state distributions\n",
    "            info_gain = torch.log(new_std / self.state_std).mean() + \\\n",
    "                       ((self.state_std ** 2 + (self.state_mean - new_mean) ** 2) / (2 * new_std ** 2)).mean() - 0.5\n",
    "            \n",
    "            rewards += self.info_gain_scale * abs(info_gain.item())\n",
    "            \n",
    "            self.state_mean = new_mean\n",
    "            self.state_std = new_std\n",
    "            \n",
    "        return rewards\n",
    "        \n",
    "    def update_curiosity_network(self, state, action, next_state):\n",
    "        # Convert action to one-hot\n",
    "        action_onehot = torch.zeros(5, device=self.device)\n",
    "        action_onehot[action] = 1\n",
    "        \n",
    "        # Predict next state\n",
    "        state_action = torch.cat([state, action_onehot])\n",
    "        predicted_next_state = self.curiosity_net(state_action)\n",
    "        \n",
    "        # Compute loss and update\n",
    "        actual_next_state = torch.FloatTensor(next_state).to(self.device)\n",
    "        curiosity_loss = F.mse_loss(predicted_next_state, actual_next_state)\n",
    "        \n",
    "        self.curiosity_optimizer.zero_grad()\n",
    "        curiosity_loss.backward()\n",
    "        self.curiosity_optimizer.step()\n",
    "        \n",
    "        return curiosity_loss.item()\n",
    "\n",
    "    def teach(self):\n",
    "        # ... [existing teach code until reward calculation] ...\n",
    "        \n",
    "        for i, e in enumerate(self.traj):\n",
    "            state, act, reward, next_state, log_prob, done, val = e\n",
    "            \n",
    "            # Compute exploration rewards\n",
    "            exploration_rewards = self.compute_exploration_rewards(\n",
    "                torch.FloatTensor(state).to(self.device),\n",
    "                act,\n",
    "                next_state,\n",
    "                state[:2]  # unit position\n",
    "            )\n",
    "            \n",
    "            # Update curiosity network\n",
    "            curiosity_loss = self.update_curiosity_network(\n",
    "                torch.FloatTensor(state).to(self.device),\n",
    "                act,\n",
    "                next_state\n",
    "            )\n",
    "            \n",
    "            # Combine rewards\n",
    "            total_reward = reward + exploration_rewards\n",
    "            \n",
    "            # ... [continue with existing teach code] ..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
